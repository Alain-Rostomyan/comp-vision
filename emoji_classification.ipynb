{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Vendor Classification\n",
    "\n",
    "This notebook trains a model to classify emoji images by their visual origin (Apple, Google, Samsung, Facebook, WhatsApp, Messenger, Mozilla).\n",
    "\n",
    "**Authors**: [Your Team Names]\n",
    "\n",
    "**Competition**: Computer Vision 2025 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running on Colab/Kaggle)\n",
    "# !pip install torch torchvision pandas numpy Pillow scikit-learn tqdm matplotlib seaborn timm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import timm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== CONFIGURATION ==============\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Paths - UPDATE THESE FOR YOUR SETUP\n",
    "DATA_DIR = Path(\"2-computer-vision-2025-b-sc-aidams-final-proj\")\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "TEST_DIR = DATA_DIR / \"test\"\n",
    "TRAIN_LABELS_PATH = DATA_DIR / \"train_labels.csv\"\n",
    "\n",
    "# For Kaggle, use:\n",
    "# DATA_DIR = Path(\"/kaggle/input/2-computer-vision-2025-b-sc-aidams-final-proj\")\n",
    "\n",
    "# Class mappings\n",
    "LABEL_TO_IDX = {\n",
    "    'apple': 0, 'facebook': 1, 'google': 2, 'messenger': 3,\n",
    "    'mozilla': 4, 'samsung': 5, 'whatsapp': 6\n",
    "}\n",
    "IDX_TO_LABEL = {v: k for k, v in LABEL_TO_IDX.items()}\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# Training settings\n",
    "IMG_SIZE = 224  # For pretrained models\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training labels\n",
    "df = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "df['label_idx'] = df['Label'].map(LABEL_TO_IDX)\n",
    "df['Id'] = df['Id'].astype(str).str.zfill(5)\n",
    "\n",
    "print(f\"Total training samples: {len(df)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "df['Label'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Vendor')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images from each class\n",
    "fig, axes = plt.subplots(2, 7, figsize=(14, 4))\n",
    "\n",
    "for idx, label in enumerate(LABEL_TO_IDX.keys()):\n",
    "    samples = df[df['Label'] == label].sample(2, random_state=SEED)\n",
    "    for row, (_, sample) in enumerate(samples.iterrows()):\n",
    "        img_path = TRAIN_DIR / f\"{sample['Id']}.png\"\n",
    "        img = Image.open(img_path)\n",
    "        axes[row, idx].imshow(img)\n",
    "        axes[row, idx].axis('off')\n",
    "        if row == 0:\n",
    "            axes[row, idx].set_title(label, fontsize=10)\n",
    "\n",
    "plt.suptitle('Sample Emojis by Vendor', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojiDataset(Dataset):\n",
    "    \"\"\"Dataset class for emoji images.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_ids, labels=None, image_dir=TRAIN_DIR, transform=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = self.image_dir / f\"{img_id}.png\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            return image, self.labels[idx]\n",
    "        return image, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=VAL_SPLIT, random_state=SEED, stratify=df['label_idx']\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = EmojiDataset(\n",
    "    image_ids=train_df['Id'].tolist(),\n",
    "    labels=train_df['label_idx'].tolist(),\n",
    "    image_dir=TRAIN_DIR,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = EmojiDataset(\n",
    "    image_ids=val_df['Id'].tolist(),\n",
    "    labels=val_df['label_idx'].tolist(),\n",
    "    image_dir=TRAIN_DIR,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EfficientNet-B0 model with pretrained weights\n",
    "model = timm.create_model(\n",
    "    'efficientnet_b0',\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    drop_rate=0.3\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate class weights to handle imbalanced data\ndef get_class_weights(df):\n    \"\"\"Calculate inverse frequency weights for each class.\"\"\"\n    class_counts = df['label_idx'].value_counts().sort_index()\n    total = len(df)\n    weights = total / (len(class_counts) * class_counts)\n    return torch.FloatTensor(weights.values)\n\nclass_weights = get_class_weights(train_df).to(DEVICE)\nprint(\"Class weights (higher = rarer class):\")\nfor idx, weight in enumerate(class_weights):\n    print(f\"  {IDX_TO_LABEL[idx]:12s}: {weight:.3f}\")\n\n# Loss with class weights, optimizer, scheduler\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\nscheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        for label, pred in zip(labels.cpu().numpy(), predicted.cpu().numpy()):\n",
    "            class_total[label] += 1\n",
    "            if label == pred:\n",
    "                class_correct[label] += 1\n",
    "    \n",
    "    class_acc = {IDX_TO_LABEL[k]: 100. * class_correct[k] / class_total[k] \n",
    "                 for k in sorted(class_total.keys())}\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total, class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    val_loss, val_acc, class_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} ({epoch_time:.1f}s)\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  -> New best model! (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training completed in {total_time/60:.1f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['val_acc'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Per-Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(best_model_state)\n",
    "_, _, class_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "print(\"Per-class accuracy on validation set:\")\n",
    "print(\"-\" * 30)\n",
    "for label, acc in sorted(class_acc.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{label:12s}: {acc:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "labels = list(class_acc.keys())\n",
    "accs = list(class_acc.values())\n",
    "plt.bar(labels, accs)\n",
    "plt.axhline(y=best_val_acc, color='r', linestyle='--', label=f'Overall: {best_val_acc:.1f}%')\n",
    "plt.xlabel('Vendor')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Per-Class Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test IDs\n",
    "test_files = sorted(TEST_DIR.glob(\"*.png\"))\n",
    "test_ids = [f.stem for f in test_files]\n",
    "print(f\"Test samples: {len(test_ids)}\")\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = EmojiDataset(\n",
    "    image_ids=test_ids,\n",
    "    labels=None,\n",
    "    image_dir=TEST_DIR,\n",
    "    transform=val_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    for images, _ in tqdm(loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "predictions = predict(model, test_loader, DEVICE)\n",
    "print(f\"Generated {len(predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved to submission.csv\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pd.Series([IDX_TO_LABEL[p] for p in predictions]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview submission\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'model': 'efficientnet_b0',\n",
    "        'img_size': IMG_SIZE,\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': NUM_EPOCHS\n",
    "    }\n",
    "}, 'best_model.pth')\n",
    "\n",
    "print(\"Model saved to best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}